---
title: 【推荐系统】流式训练
tags: 推荐系统 深度学习 笔记
published: true
---

前面介绍了推荐系统中一个请求到来时的链路，这里介绍推荐系统模型的数据是怎么来的，以及。

## 数据流

### 特征链路

<div align=center>
<img src="../../../assets/images/posts/2025-05-24/feature_serving.svg" width="60%" />
</div>

用户的所有行为都会以日志等形式写入kafka，之后根据日志类型写入不同的队列，比如点赞、点踩是一类，用户展现日志等等。用户日志非常庞杂，涉及很多数据库，时不时为了数据分析就会用SQL产生一些新表，但是统一都叫数据源。

模型用到的特征来源于数据源，需要经过比较复杂的处理流程变成Key-value服务存储到线上，比如key是user id、item id，然后value是对应user或item到一大堆特征，也是key-value。这里的处理流程通常是访问数据源获取相应的数据（比如年龄等特征），以及一些聚合操作（访问过的item序列）等等。

批式特征指定定期更新的特征，通常是每天凌晨出发对应的任务，对数据源进行处理并更新到key-value服务上。实时特征则是每来一个数据就变一下。通常来说，批式特征是用户画像、长期行为序列一类的东西，实时特征是用户短期的行为序列、地理位置这一类。

- 批式特征在进入数据库后进行处理，每天凌晨12点定时开始提取，由Hive处理变成Key-Value服务
- 实时特征则是在进入数据库前还会走另一条Flink支路，由Flink处理后直接KV化。

Flink和Hive的处理可以由SQL统一，实现流批一体的特征处理平台。



### 数据流

<div align=center>
<img src="../../../assets/images/posts/2025-05-24/data_flow.svg" width="80%" />
</div>

#### 训练样本

训练样本来源于请求。用户的每个请求都会触发召回、排序的流程，在这些流程中一方面模型会进行预测，另一方面会把它作为样本存起来。注意此时的样本是没有标签的，因为这些item都还没发送出去。之后等标签回流之后（用户点击、广告主回传的转化也被存进数据库里），这些样本和标签会拼接成训练样本（类似于SQL到join操作，根据请求的id等方法把二者对应起来），经过消息队列给模型训练。样本有一个很重要的属性是这个请求对应的时间，这些样本会按这个时间存起来，方便后续模型按天训练。

推荐系统的模型会进行批式训练和流式训练，为此需要两条数据流给两种训练准备数据，一是实时数据流，二是批式数据流。样本在拼接之后开始分流，实时数据流需要打散，然后写入kafka最后训练；批式数据写入feature store训练。

一个样本通常带有非常多的特征，这样后续就可以很方便的分析模型在不同样本上的表现，比如不同年龄段样本的表现、某类item上的表现等等。

#### One-Epoch现象

搜广推模型一般只训练一个epoch，从第二个epoch开始模型performance就会下降。有研究表明，第二个epoch的embedding梯度很小，基本就不会更新了，而MLP还会继续更新。个人的理解是稀疏特征的embedding对输入的表示能力太强、太容易过拟合了，所以MLP继续更新后很容易过拟合，导致performance下降。

One-Epoch也有个好处，就是使用流式训练不需要担心由于没有对样本过很多次导致性能损失，同时训练和测试可以一起做了，不需要划分训练集和测试集，因为反正模型也只见这个样本一次。

### 数据采样

上述介绍的训练样本用于训练模型，同样分为批式训练和实时训练。通常每天进行一次批式训练，实时的样本达到一定batch后进行一次在线更新。对于实时训练，由于样本是排队按顺序获得的，这样的样本不像离线训练会shuffle，标签可能不均匀，导致训练不稳定。

#### Fast Emit

fast emit会对纠偏造成影响。

- fast emit存在伪负例样本
- 一条样本的label是对其概率分布的采样，不用过分在意“伪负例”问题

#### DJW

#### 正例打散

### 在线训练和批式训练

* 在线训练使用flink，会把流式数据按时间窗口进行处理，然后产出数据。

* 批式训练会在预处理阶段对每天的样本进行shuffle，组装成batch，交给参数服务器训练。




## 在线优化算法

### OGD算法

其实就是SGD算法的特例：

$$
w_{t+1}=w_t-\eta_tg_t
$$

其中$\eta_t = 1/\sqrt{t}$。OGD在准确率上表现正常，但是在sparsity上表现不佳，即使加上了 L1 正则也很难使大量的参数变零。一个原因是浮点运算很难让最后的参数出现绝对零值；另一个原因是不同于批处理模式，online 场景下每次$w$的更新并不是沿着全局梯度进行下降，而是沿着某个样本的产生的梯度方向进行下降，整个寻优过程变得像是一个“随机” 查找的过程，这样 online 最优化求解即使采用L1正则化的方式， 也很难产生稀疏解。正因为 OGD 存在这样的问题，**FTRL 才致力于在准确率不降低的前提下提高稀疏性。**

### FTRL算法

[https://zhuanlan.zhihu.com/p/494715594](https://zhuanlan.zhihu.com/p/494715594)

FTRL算法希望学到的参数尽可能稀疏。FTRL引入了累计梯度，这样可以避免在线学习随机性大的问题，同时引入正则化项保证稀疏性：

$$
w_{t+1}=\text{argmin}_{w} (g_{1:t}^Tw+\frac12\sum_{s=1}^t\|w-w_s\|^2+\lambda_1 \|w\|_1+\frac12\lambda_2\|w\|^2)
$$

后面就看不懂了。。。以后再看吧。FTRL一般用来优化Wide & Deep的线性回归参数。

### AdaMom算法

$$
\begin{aligned}
g_t & \leftarrow \nabla_{\theta} J(\theta_t) + \alpha \theta_t \\
m_t & \leftarrow \beta_1 m_{t - 1} + (1 - \beta_1) g_t \\
v_t & \leftarrow \beta_2 v_{t - 1} + g_t\odot g_t \\
c_t & \leftarrow \beta_2 c_{t - 1} + 1 \\
\theta_{t + 1} & \leftarrow \theta_t - \eta \dfrac{1}{\sqrt{\dfrac{v_t}{c_t} + \epsilon}} m_t
\end{aligned}
$$

字节跳动搞的优化算法，相较于Adam，主要改动在于：二阶动量的移动平均改为上面的直接累加然后除以$c_t$，也就是取平均。这样做可以让近期梯度占比更大，更适合在线训练场景。同时在线训练的学习率也会取得很小。

### 异步优化算法

参数服务器是分布式的训练架构，需要异步的优化算法，[Delay Compensation](https://arxiv.org/pdf/1609.08326)是异步优化算法的补偿机制。第$t$时刻的梯度$g_t$可能会被用来更新$\theta_{t+\tau}$，但是正确的梯度是$g_{t+\tau}$，于是用泰勒展开可以进行近似：

$$
g_{t+\tau}\approx g_t+\nabla g_t(\theta_{t+\tau}-\theta_t)
$$

这里$\nabla g_t$是海森矩阵，可以用下面的方法近似它：

1. $g_tg_t^T$是它的一个无偏近似（$g_t$本身由于SGD的随机原因，是随机变量）
2. $\lambda g_tg_t^T$（$\lambda$是超参数，0到1之间），可以用来trade-off偏差和方差（显然越小偏差越大，方差越小）
3. 对角化trick：假设海森矩阵的非对角线元素都是0，实验效果也很好

于是把$g_t$变成：

$$
g_t+\lambda g_t\odot g_t\odot(\theta_{t+\tau}-\theta_t)
$$

就是delay compensation。

### 优化算法的选择

优化算法优化的是模型的参数，而推荐系统模型的参数通常分为2部分：embedding层的参数和神经网络的参数。神经网络的参数使用类似Adam的算法即可，而embedding参数的优化则不是，它通常占据了整个模型的绝大部分，会有千亿、万亿级别的参数量。但是它是稀疏的，一个样本总是只用到了其中极少部分参数，这意味着在每个batch对模型进行迭代的时候，只有一部分参数进行了更新，一个特征具体取值的embedding通常是迭代多次才会更新一次，也就是偶尔才会更新一次，此时使用带有momentum的优化算法就不太合适了，因此embedding的部分会使用AdaGrad算法而不是它的改进版本Adam系列算法。经过AdaGrad令人诟病的缺陷是二阶动量的累加会导致模型优化越来越慢，但是这反而契合了embedding后期很少更新的特点，除此之外，AdaGrad相较于Adam不需要维护一阶动量，减少了内存占用，这对于参数量巨大的embedding层是很重要的。


### 老汤模型

老模型训练太久，用到的数据远远多于新模型，导致新模型很难超过老模型。

一种解决办法是warm up，load以前的权重，但是这样限制了模型不能改动太大，否则load的参数作用没有那么大

每隔一段时间，重新训练模型。


## 模型稳定性

### 标签回流延迟

offline的CVR模型训练采用“种子+增量”的形式，即：在日期为t-1时，模型在前一天种子的基础上，学习t-8的样本（样本已经完全回流），得到种子模型M，在日期为t时，load种子模型M，学习[t-7,t-1]的样本（最近7天的样本，样本没有完全回流），学完后推送上线进行服务。

https://mathmach.com/5f8a539b/

模型如果直接学习最近7天的样本，将会导致模型低估，有一些解决办法：

- 采用拆塔学习的方案，**塔h_i代表的物理含义是当前样本在回流第i天的转化率**，线上预估时，使用7个head的打分相加。
- 

### 模型高估低估的影响

[https://zhuanlan.zhihu.com/p/42521586](https://zhuanlan.zhihu.com/p/42521586)

[https://blog.csdn.net/legendavid/article/details/80653433](https://blog.csdn.net/legendavid/article/details/80653433)

- 推荐系统的样本是时序的，注重实时性，注重近期数据上的AUC，一天有千万量级的数据。
- 推荐系统采用流式训练，涉及稳定性的问题，即使模型整体较高，但如果不稳定，也会有比较大的问题，尤其是广告系统，模型的预测直接关联到预算的花费。
