---
title: 生成式推荐
tags: 大模型 推荐系统
---


近年来推荐系统的研究趋势是生成式推荐，并且逐步在工业界落地。
<!--more-->

## TIGER

用transformer自回归地预测Semantic ID来进行推荐。

### Semantic ID

把Item用文本内容表示，提取单个向量作为特征。随后，用RQ-VAE转化成多ID表示。

### 自回归预测

预测出不存在的ID怎么办。


## HSTU

Meta出品的生成式推荐算法。Meta想要做一个scalable的推荐系统模型，为此需要解决三个问题：

1. 解决推荐系统大量的异构特征
2. 大量的candidates带来的推理开销
3. 流式训练带来的持续地训练开销问题

为了解决这些问题，HSTU统一了特征空间、修改了transformer模型使它更轻量以及更适合序列推荐、提出一个stochastic length的序列降采样方法来降低序列长度、设计了一个降低candidate预测计算量的方法。下面来看这些是怎么做到的。

### 统一特征序列

HSTU把行为看做一种模态，序列的构成是$<\Phi_0, a_0, \Phi_1,a_1,\cdots,\Phi_n, a_n>$的形式。

由于推荐系统有大量的异构特征，要把这些异构特征统一成这种序列的形式也不容易。HSTU采用两个核心的思路：其一，把特征里面最长的序列作为主序列，也就是把用户交互的item和行为作为主序列，其余的序列不经常变化，比如用户的关注列表，每隔一段时间压缩成一个token穿插在主序列里面；其二，抛弃一些特征，例如用户过去的点击率、用户过去行为的各种统计特征等等，这些信息本身就包含在行为序列里面，S3Rec表明模型有能力从序列中得到这些信息，因此不再使用这些特征。

#### 召回

没啥特殊的，生成embedding。

#### 排序

和TIGER直接生成的Semantic ID不同，HSTU按照传统排序的target-aware的方式去做，输入候选的item token $Phi$，然后预测它的action。个人更喜欢TIGER这种更纯粹的生成方式，后者这种感觉没有体现出生成式的优势。

跟我的论文处理多个candidate预测方法类似hhh。


### 模型结构

一层的HSTU结构为：

$$
\begin{aligned}
U, Q, K, V &\leftarrow {\rm split}(\text{Linear}(X))\\
O &\leftarrow {\rm SiLU}(QK^T+R)V \\
Y &\leftarrow \text{Linear}({\rm Norm}(O)\odot U)\\
X &\leftarrow {\rm Norm}(X + Y)
\end{aligned}
$$

其中 $R$ 表示相对位置编码的bias。与transformer相比，在attention部分，HSTU在QKV的基础上额外引入了 U，通过Hadamard积进行交叉。除此之外，attention的部分去掉了需要归一化的softmax，类似于DIN保留原始内积大小对行为序列来说效果更好，论文中的结果表明这个比softmax提了30个点。注意这里的attention也是multi-head的，公式不好表示就没有体现出来；在FFN部分，HSTU把FFN简化为了Linear层，猜测这是因为推荐系统的行为建模不需要像LLM那样用FFN层的大量参数记住很多知识。这个替换大幅减小了计算量和内存开销，把非线性更多的交给和U矩阵的乘法。另外，这种操作也可以看做是一种SwiGLU，只是门控的计算用Attention替代了。

这样的模型设计是轻量级的，很多算子的计算如Linear+Norm可以被合并到一个CUDA kernel中进行计算。

在Normalization方面，HSTU使用了post-norm，可能pre-norm会更好点？论文的实验部分提到HSTU需要比使用了softmax的HSTU和transformer小十倍的学习率进行训练。

#### Session级别样本训练

#### 序列下采样

序列是稀疏的。

### Scaling Law

TODO

## MTGR

MTGR认为HSTU抛弃了太多交叉特征，导致performance很差，即使有scaling law也无法追上交叉特征带来的增益。MTGR的核心就是保留传统推荐算法的交叉特征。


## OneRec

快手的算法。




