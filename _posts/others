强化学习：
* 单步决策问题（utility theory）
* safe exploration




- 预训练
    - CV
        - 对比学习：MoCov1→MoCov3，SimCLR，BYOL，DINOv2
        - BEiT，MAE
    - NLP：BERT，RoBERTa，DeBERTa

- 多模态
  - LXMERT，UNITER，早期论文，还在用检测网络，各种花里胡哨的task
  - 2021 VILT：经典论文，图片和文本concat一起训，效果就很好，就是收敛慢。
  - 2021 ALBEF：经典论文，2个模态的encoder+1个cross attention融合模块，核心是引入CLS的预对齐
  - 2021.02 CLIP：简单粗暴的对比学习
  - 2022 VLMo：指出FFN层可以替换
  - 2022 Coca：和ALBEF结构类似，但是训练任务从MLM改成了文本生成以支持更多任务
  - 2022.01 BLIP：3个loss，caption+contrastive+itm，外加bootstrap的数据
  - 2022 BEiTv3：统一的完形填空训练任务

      BEiTv1就是引入dVAE进行MIM的训练，BEiTv2引入了teacher的监督，BEiT引入了多模态，统一用完形填空训练（还包括MultiWay Transformer）。

      - BEIT v3除了BERT外还有别的特殊的设计吗
      - V3和V2的 embbeding有什么不同
  - 2023.03 SigLIP：用sigmoid计算loss的CLIP

  后面是大模型[https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)

  - 2022.04 Flamingo：多模态领域最早期的尝试做类似于GPT的few-shot的论文。弄了一个类似于QFormer的东西（感知重采样层），以及门控机制。以如今的视角来看没有必要。
  - 2023 BLIP2：QFormer+大模型，感觉从这里开始就明显的是Adapter的时代了。
  - LLaVA
      - 模型没啥特点，图片用ViT提特征之后加linear层输入到LLM，两阶段训练。
      - LLaVa Next：图片分块+Resize整体获取局部整体特征，OCR改进模型
  - Intern-VL：
  - QWen-VL：
  - DeepSeek-VL
  - 多模态大模型总结
      - 模态的编码，LLM的backbone，以及多模态的生成
      - Input Projector

- 大模型
  - pretraining
      - 神中神的文章：[https://zhuanlan.zhihu.com/p/718354385](https://zhuanlan.zhihu.com/p/718354385)，贼详细。
      - pretrain监控
          - 监控不同类型数据上的loss
          - 异常现象
              - loss spike：脏数据，or，调adamw的beta1和beta2参数
              - loss突然下降，应该是重复数据
      - 数据
          - 网页、新闻、各种文章、书籍、论文、代码、markdown、latex等等

          - 数据清洗流程
            - 过滤
                - 用BERT训一个打分器过滤
                - 规则过滤（例如过滤反动、黄色字眼，过滤某一token占比过高的文本）
                - 数据脱敏
            - 去重
                - 最好能做句子级别的去重，但是计算量太大，一般用文档级别的去重。计算资源足够就用更细的粒度去重
                - 去重用minHash，先确定需要的数据量，再确定筛选的阈值
            - 数据分类
                - 训一个BERT模型进行数据分类
                - 知识、代码、逻辑
                - 中文、英文、code
            - 数据顺序
                - 原则是把简单的数据放前面，难的方后面，也就是课程学习。但是怎么做到这一点？训练一个小学、初中、高中、大学的分类模型？
            - 数据流水线
                - 先把数据全部tokenize存起来
                    - tokenizer训练
                    - 手动移出脏词
                    - 人为补充词语
                - 然后训练的时候，每次读一个数据块到内存，用这个数据块训练，训完之后save checkpoint方便回退
  - post training
      - 训练方法
          - RLHF，PPO，GRPO
          - DPO如何解决回答过长的问题？除了正则？DPO还有哪些常见问题？SIMPO如何解决DPO微调导致的序列过长问题？
          - DPO的对齐训练曲线是怎么样的？正例的概率会提升吗？
          - base模型如何增强推理能力？
  - 大模型评估
      - PPL取对数就是交叉熵loss了
      - 评测指标：
          - Code：Pass@k指标，是让大模型做OJ题目，生成k个答案，如果有一个通过了，记为1，否则为0。

              比如在OpenAI的HumanEval上评测，对应的论文。

              详细的介绍：[https://zhuanlan.zhihu.com/p/653063532](https://zhuanlan.zhihu.com/p/653063532)
          - 常识、世界知识、阅读理解，这些都是选择题
          - 数学题，也是看正确率
      - 概率探针
      - 如何评估LLM的效果和大模型性能？
      - 如何提高硬件利用率，如何高效使用计算资源？合理的设置模型大小

- 基建
  - ZeRO
  - DeepSeed的每一段通信比较，ZeRO3分别是0和2的多少倍？
  - DeepSeed框架与不同训练阶段的区别，以及它们的优缺点。
  - 模型训练时间估算
  - 数据并行，和分布式数据并行
  - 如何进行有效的模型监控？保证训练顺利进行
  - tensorRT
  - fp16和fp32，混合精度训练，介绍下

- RAG
  - 检索增强

- workflow

  决策，自动化。

  - 典型的workflow应用
      - 自动化报销审批
      - 翻译
  - 歧义消解
  - 意图识别

- Agent
  - 指令、记忆、工具
      - 指令
      - 记忆：长期记忆、短期记忆
      - 工具：互联网搜索、RAG、python解释器、其它API
  - 典型应用
      - 知识库问答
      - 数据分析
      - Deep Research



- 怀旧的东西补补
    - PEFT

    - 类别不均衡问题
      - 解决办法
          - 重采样、loss加权、Focal Loss
          - Long-Tail Learning via Logit Adjustment
          - Dynamic Curriculum Learning for Imbalanced Data Classification
      - 长尾问题的理解

          [https://www.zhihu.com/question/654186093/answer/3483543427](https://www.zhihu.com/question/654186093/answer/3483543427)
      - 推荐系统中的长尾问题，embedding的使用率长尾

          [https://zhuanlan.zhihu.com/p/443825382](https://zhuanlan.zhihu.com/p/443825382)

          WhitenningBERT。

          类别不均衡对embedding的影响。
- 前沿的东西看看
    - VGGT

        [https://imaging.cs.cmu.edu/volumetric_opaque_solids/](https://imaging.cs.cmu.edu/volumetric_opaque_solids/)
    - Agent应用：CUI、智能编排
        - [https://www.swebench.com/](https://www.swebench.com/)
        - [https://www.coze.com/](https://www.coze.com/)
        - 结合parser转文本交给大模型做
        - prompt→function call→MCP
        - Deep Search
- DeepSpeed使用学习





